{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick start for fitting and using the DREAM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Specify your settings here, including the full path to the `olfaction_prediction` folder (probably two levels above this file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where is your olfaction_prediction folder?\n",
    "OP_PATH = '/path/to/olfaction-prediction'\n",
    "OP_PATH = '/mnt/d/Dropbox (ASU)/science/olfaction-prediction'\n",
    "OP_PATH = '/Users/rgerkin/Dropbox (ASU)/science/olfaction-prediction'\n",
    "\n",
    "# Which feature sets do you want to use?\n",
    "FEATURE_SETS = ['dragon', 'episuite', 'morgan', 'nspdk', 'gramian']\n",
    "\n",
    "# Which datasets do you want to train on?\n",
    "TRAIN_ON = ['training', 'leaderboard']\n",
    "\n",
    "# Which datasets do you want to test on?\n",
    "TEST_ON = ['testset']\n",
    "\n",
    "# Which subjects do you want to build a model for (or for the mean or stdev across subjects)\n",
    "SUBJECT = 'Mean' # Other options are 'StDev' or an integer subject number\n",
    "\n",
    "# What dilution do you want to evaluate model quality on (other dilutions will still be used for training)\n",
    "DILUTION = 'gold' # An integer (e.g. -3 for 1:1000) or the values 'high', 'low', or 'gold'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in or external libraries\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds olfaction-prediction directory from environment or user variable to the Python path\n",
    "OP_PATH = os.environ.get('OP_PATH', OP_PATH)\n",
    "sys.path.append(OP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Internal libraries\n",
    "import opc_python\n",
    "# For loading data into dataframes\n",
    "from opc_python.utils import loading\n",
    "# dream contains lots of important functions related to model building\n",
    "# fit2 is specifically subchallenge 2 related (fitting mean and stdev) when the data is ready\n",
    "# params contains functions for obtaining or looking up previously obtained hyperparameters\n",
    "from opc_python.gerkin import dream, params, fit1, fit2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all descriptor names\n",
    "descriptors = loading.get_descriptors(format=True)\n",
    "\n",
    "# Get all CIDs from the DREAM dataset\n",
    "all_CIDs = loading.get_CIDs([TRAIN_ON, TEST_ON])\n",
    "\n",
    "# Get all CIDs and dilutions for training data\n",
    "# CID + dilution completely defines the stimulus, and can be used for filtering the data\n",
    "# May take a few seconds the first time it is run, then uses a pickled file for better performance\n",
    "all_CID_dilutions = loading.get_CID_dilutions([TRAIN_ON, TEST_ON])\n",
    "training_CID_dilutions = loading.get_CID_dilutions(TRAIN_ON)\n",
    "testing_CID_dilutions = loading.get_CID_dilutions(TEST_ON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dragon has 4869 features for 476 molecules.\n",
      "Episuite has 62 features for 476 molecules.\n",
      "Morgan has 2437 features for 476 molecules.\n",
      "Nspdk has 6163 features for 476 molecules.\n",
      "Gramian has 2437 features for 476 molecules.\n",
      "There are now 15968 total features.\n"
     ]
    }
   ],
   "source": [
    "# Get all molecular data, i.e. physicochemical features\n",
    "molecular_data = loading.get_molecular_data(FEATURE_SETS, all_CIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all perceptual data, i.e. odor ratings\n",
    "perceptual_data = loading.load_perceptual_data([TRAIN_ON, TEST_ON])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Build the matrix of predictors and the vectors of target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X matrix now has shape (952x8011) molecules by non-NaN good molecular descriptors\n"
     ]
    }
   ],
   "source": [
    "# Create the X matrix from the molecular data in the training set.\n",
    "# Several other arguments are available; see dream.py\n",
    "X, metadata = dream.make_X(molecular_data, all_CID_dilutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the Y matrix from the perceptual data in the training set.\n",
    "# Several other arguments are available; see dream.py\n",
    "Y = dream.make_Y(perceptual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 42 CID/dilution combinations for which we have molecular data but not perceptual data. \n"
     ]
    }
   ],
   "source": [
    "print((\"There are %d CID/dilution combinations for which we have molecular data but not \"\n",
    "       \"perceptual data. \") % len(set(X.index).difference(Y.index)))\n",
    "\n",
    "# Remove those CID/dilution combinations from the molecular data\n",
    "X = X.loc[Y.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the testing CID/dilutions combinations to reflect this\n",
    "testing_CID_dilutions = list(set(testing_CID_dilutions).intersection(Y.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above number may be greater than 0 if some of the testset CID/dilution combinations were not present in the DREAM challenge data, for example molecules for which the highest tested concentration was 1/1000, so this concentration was used for all descriptors in the challenge, and thus the data for the lower concentration was never reported. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have 814 CID/dilution combinations for training and 96 for testing\n"
     ]
    }
   ],
   "source": [
    "X_train = X.loc[training_CID_dilutions]\n",
    "X_test = X.loc[testing_CID_dilutions]\n",
    "Y_train = Y.loc[training_CID_dilutions]\n",
    "Y_test = Y.loc[testing_CID_dilutions]\n",
    "assert X_train.shape[0] == Y_train.shape[0]\n",
    "assert X_test.shape[0] == Y_test.shape[0]\n",
    "print(\"We now have %d CID/dilution combinations for training and %d for testing\" \\\n",
    "      % (X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for perceptual training data\n",
    "Y_imp = dream.impute(Y_train, 'median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Load previously computed hyperparameters for model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>use_et</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>regularize</th>\n",
       "      <th>use_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intensity</th>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pleasantness</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bakery</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweet</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruit</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             use_et max_features max_depth min_samples_leaf regularize  \\\n",
       "Intensity      True         None      None                1        0.8   \n",
       "Pleasantness  False         None      None                1        0.7   \n",
       "Bakery        False         None         6                1        0.9   \n",
       "Sweet         False         None      None                1        0.8   \n",
       "Fruit         False         None        15                1        0.8   \n",
       "\n",
       "             use_mask  \n",
       "Intensity       False  \n",
       "Pleasantness    False  \n",
       "Bakery          False  \n",
       "Sweet           False  \n",
       "Fruit           False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load hyperparameters previously obtained via cross-validation\n",
    "# use_et = use ExtraTrees instead of RandomForest\n",
    "# regularize = balance between subject-specific fits and population fits (not used for mean prediction)\n",
    "# use_mask = use masked data instead of imputed data for training\n",
    "hp = params.get_hyperparams('Mean')\n",
    "hp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine translation parameters \n",
    "# (for translating mean predictions into standard deviation predictions)\n",
    "trans_params = params.get_trans_params(Y, descriptors, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Fit the models for each descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-----------------------100%---------------------] 21 out of 21 complete (All descriptors' models have been fit)\n"
     ]
    }
   ],
   "source": [
    "# Increase n_estimators to get better fits; full model uses ~100.  \n",
    "# Set std to True to also predict standard deviations\n",
    "models = fit2.rfc_fit_models(X_train, Y_train, Y_imp, hp, n_estimators=25, std=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Make predictions on the testset data for each model and descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted ratings using the models applied to the test molecular data, restricted to DILUTION\n",
    "predicted = fit2.rfc_get_predictions(models, X_test, dilution=DILUTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Check predictions against testset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the observed data for the test molecules, restricted to DILUTION\n",
    "observed = fit2.get_observed(Y_test, dilution=DILUTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R = 0.704 for Intensity\n",
      "R = 0.568 for Pleasantness\n",
      "R = 0.522 for Bakery\n",
      "R = 0.645 for Sweet\n",
      "R = 0.589 for Fruit\n",
      "R = 0.743 for Fish\n",
      "R = 0.796 for Garlic\n",
      "R = 0.648 for Spices\n",
      "R = 0.186 for Cold\n",
      "R = 0.57 for Sour\n",
      "R = 0.581 for Burnt\n",
      "R = 0.418 for Acid\n",
      "R = 0.474 for Warm\n",
      "R = 0.584 for Musky\n",
      "R = 0.556 for Sweaty\n",
      "R = 0.337 for Ammonia\n",
      "R = 0.415 for Decayed\n",
      "R = 0.303 for Wood\n",
      "R = 0.499 for Grass\n",
      "R = 0.661 for Flower\n",
      "R = 0.141 for Chemical\n"
     ]
    }
   ],
   "source": [
    "# For each descriptor, print the Pearson correlation between the predicted and observed ratings\n",
    "for descriptor in descriptors:\n",
    "    p = predicted['mean'][descriptor]\n",
    "    o = observed['mean'][descriptor]\n",
    "    r, p = pearsonr(p, o)\n",
    "    print('R = %.3g for %s' % (r, descriptor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
